0.不同的公司、不同的人做出的 RPC 框架，架构设计思路都差不多，最后实现的功能也都差不多。
但是有的人做出来的框架，Bug 很多、性能一般、扩展性也不好，只能在自己公司仅有的几个项目里面用一下。
而有的人做的框架可以开源到 GitHub 上给很多人用，甚至被 Apache 收录。为什么会有这么大的差距呢？

这是因为，数据结构和算法是相辅相成的。数据结构是为算法服务的，算法要作用在特定的数据结构之上。
因此，我们无法孤立数据结构来讲算法，也无法孤立算法来讲数据结构。比如，因为数组具有随机访问的特点，常用的二分查找算法需要用数组来存储数据。但如果我们选择链表这种数据结构，二分查找算法就无法工作了，因为链表并不支持随机访问。
数据结构是静态的，它只是组织数据的一种方式。如果不在它的基础上操作、构建算法，孤立存在的数据结构就是没用的。

这里面有
10 个数据结构：数组、链表、栈、队列、散列表、二叉树、堆、跳表、图、Trie 树；
10 个算法：递归、排序、二分查找、搜索、哈希算法、贪心算法、分治算法、回溯算法、动态规划、字符串匹配算法。

1.比如，我们常用的 Key-Value 数据库 Redis 中，里面的有序集合是用什么数据结构来实现的呢？
为什么要用跳表来实现呢？为什么不用二叉树呢？

2.如何实时地统计业务接口的 99% 响应时间？你可能最先想到，每次查询时，从小到大排序所有的响应时间，
如果总共有 1200 个数据，那第 1188 个数据就是 99% 的响应时间。很显然，每次用这个方法查询的话都要排序，效率是非常低的。
但是，如果你知道“堆”这个数据结构，用两个堆可以非常高效地解决这个问题。

3.因为事后统计法并不完备，我们需要引入复杂度分析
为什么不完备？
1》测试结果非常依赖测试环境，我拿8G机器跑和16G机器跑，结果不一样
2》测试结果非常依赖数据规模：我跑1w数据和1000w数据，结果不一样
速度快-时间复杂度
省空间-空间复杂度
大O复杂度表示法
T(n)=O(f(n))

渐进式时间复杂度分析
1》只关注循环执行次数最多的一段代码
2》加法法则：总复杂度等于量级最大的那段代码的复杂度
3》乘法法则：嵌套代码的复杂度等于嵌套内外代码复杂度的乘积

4.在大部分编程语言中，数组都是从 0 开始编号的，但你是否下意识地想过，
为什么数组要从 0 开始编号，而不是从 1 开始呢？ 从 1 开始不是更符合人类的思维习惯吗？
解答：
现在我们来思考开篇的问题：为什么大多数编程语言中，数组要从 0 开始编号，而不是从 1 开始呢？
从数组存储的内存模型上来看，“下标”最确切的定义应该是“偏移（offset）”。
前面也讲到，如果用 a 来表示数组的首地址，a[0]就是偏移为 0 的位置，也就是首地址，
a[k]就表示偏移 k 个 type_size 的位置，所以计算 a[k]的内存地址只需要用这个公式：
a[k]_address = base_address + k * type_size

5.缓存淘汰的策略有3种
1》FIFO
先进先出

2》LRU
Least Recent Use
最近最少使用

3》LFU
Least Frequent Use
最少使用

6.链表Linked List
1》单链表
->data-next->data-next->data-next->data-next->null

2》双链表
耗内存，但是查询和删除比但链表更快，既存了prev，又存了next，用空间换时间
LinkedHashMap
->pre-data-next->pre-data-next->pre-data-next->pre-data-next
->pre-data-next<-pre-data-next<-pre-data-next<-pre-data-next

3》循环链表
尾节点的指针不指向null了，指向头结点，这就是首尾相连的环
约瑟夫问题
->data-next->data-next->data-next->data-next->null

